1、数据三范式
    1、每个列都不可再分, 不能在分成多个意义的列。
    2、在满足第一范式的基础上, 非主键列要完全依赖于主键, 而不能依赖于主键的一部分。(不能有部分依赖)
    3、在满足第二范式的基础上, 非主键列只能依赖于主键, 不能依赖于非主键列。(不能有传递依赖)
    在实际开发中, 尽量以三范式设计数据库。可能会因为提高性能等情况, 不满足某个范式。
2、MySQL的binlog有几种写入格式
    有三种, statement、row、mixed
    1、statement模式, 每一条会修改数据的SQL都会记录在binlog日志中。不需要记录每一行的变化, 减少了binlog日志量, 减少IO, 提高性能。某些函数语句不会被记录下来。
    2、row模式, 不会记录SQL语句的上线文信息, 仅保存了那条记录被修改。记录单元为每一行的改动。基本上可以全部记下来。但由于操作过度, 导致日志量太大。
    3、mixed模式, 一种折中方式, 普通操作会使用statement记录, 当无法使用statement时, 使用row方式记录。
3、MySQL存储引擎
    1、MyISAM 与 InnoDB区别
        1、存储结构:
            MyISAM使用三个文件存储数据库表。.frm存储表结构、.MYD存储表数据、.MYI存储索引(对应非聚簇索引, 索引和数据分开存储)。
            InnoDB默认所有表的数据全部存储在一个文件中(通过修改配置使每个表分开存储)。(数据和索引存储在一个文件中, 对应聚簇索引)
        2、是否支持外检
            MyISAM不支持, InnoDB支持。
        3、是否支持事务
            MyISAM不支持, InnoDB支持。
        4、锁的颗粒度
            MyISAM只支持表级锁, InnoDB支持表级锁和行级锁。表级锁在高并发下, 更容易产生冲突, 行级锁的高并发性能更好。
        5、适用场景
            MyISAM适用于select查询操作较多的情况。InnoDB更适用增删改和根据索引查询数据较多的情况。
        6、索引的实现方式
            MyISAM和InnoDB都是用B+树实现索引和数据存储。MyISAM适用的堆表, InnoDB适用的是索引组织表。
4、InnoDB存储引擎
    1、四大特性
        1、插入缓冲
        2、二次写
        3、自适应哈希索引
        4、预读
5、索引
    索引是组织数据存储的一种数据结构。可以优化数据存储方式, 提高数据的查询性能。在MySQL中适用B+树作为索引和数据的存储结构。
    当数据量较大时, 可以针对性的建立索引, 来提高数据的检索性能。
    1、分类
        1、唯一索引: 该列值唯一, 有且只有一个值为null。
        2、主键索引: 唯一索引的一种, 并且不允许有null值。一个表中只允许有一个主键索引。
        3、普通索引: 在非主键列上建立的索引。没有唯一性限制, 并且可以有多个null值。
        4、组合索引: 使用多列一起建立索引。(使用时, 尽量符合最左匹配原则, 提高性能)
        5、全文索引: 对于文本型列建立的索引, 调高文本型列的查询性能。搜索引擎使用的关键技术。
    2、如何创建索引
        1、区分度不高的列, 不应该创建索引。如性别。最好使用离散值较大的字段, 重复性越低, 越适合建立索引。
        2、更新较为频繁的列, 不适合创建索引。对于更新操作, 修改索引值, 需要对索引B+树进行调整, 频繁修改浪费性能。
        3、频繁作为查询条件的列更适合建立索引。
        4、可以使用多列创建组合索引。但使用时, 最好遵循最左匹配原则, 防止有组合索引中某些列无法使用索引。提高组合索引性能。
        5、创建索引时, 列中值最好是非空。含有空值的索引很难进行优化, 索引的统计信息和比较运算更加复杂。最好使用特殊值代替。
        6、索引列越小越好, 增加读取非叶子节点的个数, 数据库的数据存储是以页为单位, 每页存储的节点数量越多, IO次数越少, 效率越高。优化的本质是减少IO次数和IO数据量。
    3、使用索引一定能提高查询性能么?
        通常来说使用索引检索数据性能更高。但是使用索引也是有代价的。索引是存储在磁盘上的, 需要进行维护, 每当数据库记录被增减或索引列被修改时, 都要维护索引的B+树。
        所以某些不必要的索引会降低数据库的性能。
        对于百万级别的数据删除时:
            1、先删除表上的索引。
            2、再将需要删除数据删除。
            3、删除完成后重新建立索引。
    4、前缀索引
        使用某个列上前一些字符作为索引。默认索引是以整个字段作为索引的。可以通过公式进行确认需要前多少为作为前缀索引。越能区分记录, 越少位数, 越好。
    5、什么是最左匹配原则
        简单说就是最左优先, 在查询语句中创建组合索引时, 越频繁的查询条件应该放在越左边。MySQL对于查询条件, 会一直向右匹配, 知道出现范围查询, 就停止匹配。
        对范围查询条件和前面的查询条件使用索引(如果都有索引的话), 范围查询后的查询条件将不使用索引。所以查询条件的顺序也会影响查询性能。
        为什么要按照顺序进行查?
        因为对于组合索引来说, 在B+树上, 是最左边的列以此组合有序的, 先以第一列排序, 第一列相同, 再以第二列排序, 以此类推。所以如果单独以第二列及之后的作为排序, 不能使用索引
        的顺序, 如果想以索引的顺序作为最后结果的顺序, 那么必须保证左侧列存在。
    6、B树于B+树
        1、区别: B树的所有节点都会存储索引和数据的关系, 检索数据时, 可以直接查询出数据, 更适合随机查询。但对应的存储空间变大, 导致每次读取的数据页中包含的节点数量减少, 会增加IO次数。
        在B+树种, 数据全部存储在叶子结点中, 非叶子结点只存储索引值及子节点的指针。要检索到数据需要定位到具体的某个叶子节点。由于非叶子节点减少数据的存储, 会使数据页包含更多
        的节点, 可以减少IO次数。适合随机查询和范围查询。并且B+树中, 所有叶子结点会以链表的形式链接并且由于索引是有序的, 索引更加适合范围性查询。只要查询到起始结点, 之后就可以在叶子结点的链表上
        向后遍历, 而不需要读取非叶子结点。
        2、B+树查询效率更稳定, 所有数据全部存储在叶子结点中, 每条记录查询过程都是跟到叶子结点的一条路径, 不同索引值得效率差不多。B树 查询数据时, 也是
        从根节点开始查询, 但是因为所有结点都会存储数据, 所以越靠近根节点, 查询速度越快, 查询效率不稳定。
    7、Hash索引和B+树索引
        1、Hash索引底层使用Hash表存储数据, 在查询数据时, 需要计算索引的hash值, 再进行回表操作查询出数据记录。而B+树查询数据时, 都是从根节点开始向下查找数据。
        2、Hash索引适用于等值查询, 对于范围查询, 以为索引都是经过hash函数计算, 所以无序, 只能全表扫描, 并且因为索引无序, 在排序时需要额外进行排序操作。
        而B+树索引对于等值查询, 会根据索引值从根节点开始查找, 对于范围查询只需要找到起始结点, 之后使用叶子结点链表进行查询, 范围查询性能较好。并且由于B+树上索引有序,
        如果排序是根据索引列的话, 那么查询结果就是有序的, 不需要进行二次排序。
        3、Hash索引不支持模糊查询和多列的最左匹配查询, 因为查询时是对索引计算了hash值, 再进行查找。
        4、Hash查询数据时需要回表操作, B+树某些情况不需要(主键, 唯一键、或自动生成的主键的聚簇索引; 覆盖索引)回表操作。
        5、Hash索引由于使用hash函数计算hash值, 那么当数据量较大时, 可能会出现hash冲突, 性能不稳定。而B+树比较稳定, 每次查询都是从根节点开始, 并且数据量较大时,
        树的高度较低。
    8、聚簇索引与非聚簇索引
        1、聚簇索引: 将索引和数据存储在一起, 找到索引也就找到数据了。
        2、非聚簇索引: 将索引和数据分开存储, 索引只和记录的主键对应存储在一起, 当找到索引时, 需要使用对应主键进行回表操作, 查询到最终记录。
        3、使用场景
            1、聚簇索引: 范围查询
            2、非聚簇索引: 频繁更新的列
        4、非聚簇索引一定会回表么?
            不一定, 对于单列索引, 叶子结点存储的是索引和主键的对应关系, 如果查询主键或者统计记录数, 那么此时可以直接返回主键或记录数, 就不用回表。如果对于组合索引,
            如果查询列全部包含在组合索引中, 那么也不需要回表。简单的说查询列是索引的一个子集, 那么就可以直接返回结果, 不需要回表。
6、事务
    1、什么是数据库事务?
    数据库事务是一些不可分割的操作, 这些操作要么全都成功执行, 要么都不执行。是数据库并发控制的基础。其执行结果必须从一个一致性状态到另一个一致性状态。如转账。
    2、ACID
        1、原子性
            一个事务中的所有操作, 要么全部都成功执行, 要么都不执行。
        2、一致性
            事务执行前后, 需要保证一致性状态。执行结果必须从一个一致性到另一个一致性。通过原子性、隔离性、持久性保证。
        3、隔离性
            不同事务之间互不影响。通过事务隔离级别、锁来保证。
        4、持久性
            如果事务成功执行, 那么事务中对数据库的操作将会永久的保存。通过日志系统保证。
    3、数据不一致性
        1、脏读: 一个事务读取到另一个事务未提交的数据, 由于另一个事务所做的修改未提交, 随时可能回滚, 所以这部分数据具有不确定性, 称为脏数据。
        2、不可重复读: 一个事务读取到了另一个事务提交的数据, 到这当前事务中, 两次读取到的数据不一致。
        3、幻读: 当前事务两次范围行查找, 第二次结果比第一次结果记录数量不一致。
    4、事务的隔离级别
        1、读未提交: 当前事务可以读取到其他事务未提交的数据。数据库事务中最低级的隔离级别。可能会出现脏读、不可重复读、幻读。
        2、读已提交: 当前事务可读取其他事务提交之后的数据。可以避免脏读。可能会出现不可重复读、幻读。
        3、可重复读: 在当前事务中, 除当前事务修改外, 对于同一个字段多次读操作的结果相同。可以避免不可重复读。可能会出现幻读。
        4、序列化: 最高的事务隔离级别。所有事务串行执行, 可以避免所有数据不一致性。
        MySQL默认的事务隔离级别是可重复读, 可以防止脏读、不可重复读。并且使用间隙锁来保证不不出现幻读。
        事务隔离机制基于锁和并发调度实现。其中并发调度使用的是MVCC(多版本并发控制), 通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。
7、锁
    1、锁是对资源并发访问控制、防止产生数据不一致性的一种机制。
    2、表级锁、行级锁、页级锁
        1、根据锁的颗粒度可分为 表级锁、行级锁、页级锁
        2、MyISAM使用的是表级锁, InnoDB默认使用行级锁同时支持表级锁。
        3、行级锁, 是MySQL颗粒度最小的锁。表示只对当前操作的行加锁。实际是通过对索引进行加锁。行级锁可以大大减少数据库并发冲突。但是开销较大, 加锁慢。并发性能好。
        分为共享锁和排它锁。可能会出现死锁。
        4、表级锁, 是MySQL颗粒度最大的锁。表示对当前操作的整张表进行加锁。开销小, 加锁块。但容易出现锁冲突。不会出现死锁。分为表共享杜锁和表独占写锁。并发性能低。
        5、页级锁, MySQL介于行级锁和表级锁的一种颗粒度。一次锁定相邻的一组数据。性能介于两者之间。
    3、共享锁和排他锁
    4、InnoDB存储引擎的锁算法
        1、Record Lock:记录锁, 对单行记录上锁。
        2、Gap Lock: 间隙锁, 锁定一个范围, 不包括记录本身。
        3、Next-Key Lock: Record Lock + Gap Lock锁定一个范围, 包含记录本身。
    5、死锁
        1、死锁是指两个或多个事务在同一资源上的相互占用, 并且请求对方资源。从而导致的循环等待现象。
            死锁产生的4个必要条件
            1、互斥： 某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
            2、占有且等待： 一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
            3、不可抢占： 别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
            4、循环等待： 存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。
        2、常见的解决方式
            1、如果不同程序并发存取多个表, 尽量约定相同的访问顺序。可以大大降低死锁的机会。
            2、如果在同一个事务中, 尽可能一次性锁定所有需要的资源。减少死锁产生的概率。
            3、对于非常容易产生死锁的部分, 可以提升锁的颗粒度, 使用表级锁, 减少减少死锁产生的概率。
        3、乐观锁与悲观锁
            1、数据库中并发控制的目的是确保多个事务存取数据库中同一数据不破坏数据库的隔离性、一致性。乐观并发控制和悲观并发控制是并发控制主要采用的手段。
            2、悲观锁: 假设会发生并发冲突, 屏蔽一切可能违反数据库完整性的操作。在查询数据的时候就将事务锁起来, 直到事务完成。使用数据库的锁机制实现。
            3、乐观锁: 假设不会发生并发冲突, 只在提交事务的时候检查是否违反事务的完整性。在修改数据的时候把事务锁起来。通过版本控制的方式来进行锁定。
            使用版本控制机制和CAS算法实现。更适用于多读的场景, 这样冲突较少, 减少加锁开销。
8、常用的SQL语句
    1、DDL: 数据库定义语言, 对逻辑结构有操作的, 包括表结构、视图、索引。CREATE、DROP、ALTER
    2、DML: 数据库操作语言, 对数据库的增删改操作。INSERT、DELETE、UPDATE。
    3、DCL: 数据库控制语言, GRANT、REVOKE、COMMIT、ROLLBACK。
    4、DQL: 数据库查询语言, 即select语句。
9、数据库约束
    非空约束、主键约束、唯一约束、检查约束、外键约束、默认约束(规定默认值)
10、SQL优化
    1、使用Explain执行计划, 查看SQL语句执行情况。以此进行优化。
        1、根据type确定范文类型, 是全表扫描、还是范围查询等。一般需要达到range级别及以上。
        2、key使用的索引, 如果为null表示没有使用索引, 可以考虑SQL语句编写问题导致没有使用索引, 或者考虑建立索引。
        3、key_length表示使用索引时, 索引占用空间大小。结果相同时, 越小越好。
        4、extra
            1. Using index 使用覆盖索引
            2. Using where 使用了用where子句来过滤结果集
            3. Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。
            4. Using temporary 使用了临时表, 尽量优化。
    2、数据量较大的表, 如何优化
        1、优化表设计, 例如增加冗余字段减少表连接, 增加索引等。
        2、增加缓存, 8之前可以直接使用MySQL作为查询缓存, 8取消了缓存, 可以适用memcached, redis作为查询缓存。查询缓存比较适用于大量读取操作, 比较容易命中缓存。
        如果是更新操作过多的话, 每次更新都会重新刷新缓存, 浪费性能。
        3、主从复制, 读写分离。将查询于读取操作分离。
        4、分库分表。对于多服务进行分库, 不同服务访问不同库, 减少同一数据库并发量。对于表数据量较大使用水平或垂直进行分表。(但是要考虑分布式事务、唯一主键、排序等)
    3、SQL优化过程
        1、开启慢查询, 设置慢查询时间, 定位慢查询语句。
        2、从表设计上, 是否可以冗余字段, 减少表连接操作; 使用自增主键, 减少B+维护成本(主键索引是聚簇索引, 所有数据存储在叶子节点中, 插入一个新元素如果主键是自增的, 那么直接在末尾插入即可,
        如果非自增主键, 需要移动原来部分节点, 浪费性能。并且使用自增有序得主键也可以优化Limit, 避免跳过大量记录数。); 固定长度列, 如密码, 使用Char而不Varchar, 减少空间。
        3、从业务逻辑上, 减少不必要的字段查询, 尽量使用覆盖索引, 减少回表; 对于索引的处理操作从SQL中移植业务代码中, 以免在SQL中无法使用索引; 使用Limit限制查询条数等。
        4、从索引上, 对于慢查询语句, 执行explain, 查看执行计划。
        5、查看是否使用索引, 是否额外进行排序等。针对执行计划进行优化处理, 让SQL尽量命中索引。
        6、对于where字句的优化
            1、避免全表扫描, 应该在where和group by字句中设计的列建立索引。
            2、应该避免在where中使用null判断、or、不等于、in、not in等查询条件, 导致MySQL放弃使用索引, 进行全表扫描。
            3、对于模糊查询, 尽量使用前缀索引来查询, 如果一定要前端like的话, 可以考虑全文索引。
            4、避免在where字句中, 对索引列进行函数操作, 导致放弃使用索引, 进行全表扫描。
        7、数据库优化
            1、数据量非常大, 考虑分库分表。
    4、查询MySQL服务CPU高占用过程
        1、使用top命令, 判断是否是mysqld服务造成的CPU高占用。
        2、使用show processlist命令, 查看那些线程导致高占用。
        3、找出具体耗费资源的SQL, 参考执行计划, 优化SQL。
    5、千万级别数据表优化
        当MySQL单表数据量过大时, 会导致CURD的性能明显下降。需要考虑对数据库表进行优化。
        1、尽量待条件进行查询数据。
        2、使用主从复制, 读写分离, 主库负责写数据, 从库负责都数据。
        3、对于更新较少的数据, 可以考虑使用缓存。如Redis。
        4、分库分表
            1、分库: 更具不同服务, 访问不同数据库。减少单库的连接请求。
            2、分表: 单库分表(在一个库中, 将表拆分成多个)、读库分表(将表拆分到多个数据库)
                1、垂直拆分
                    根据表中列的相关性, 差分成多个表, 每个表包含原表的部分列。拆分的是表结构。
                2、水平拆分
                    规定记录数进行差分表。如500万条记录拆分出一个表、每月的记录数拆分成一个表(可以设置定时任务)、每日的记录数拆分成一个表。拆分的是数据。
                3、垂直与水平拆分的区别
                    1、垂直拆分, 拆分的是表结构。多表的表结构不同, 记录数相同。水平拆分, 拆分的是数据。多表的表结构相同, 记录数不同。
                    2、垂直拆分可以减少行数据大小, 读取时每页可以包含更多数据, 减少IO次数。但会在多张表冗余主键, 使用连接查询。可以考虑在应用程序中进行连接操作。
                    垂直拆分, 会导致事务更加复杂。
                4、分库分表, 会带来应用程序的复杂行, 如跨节点连接查询(可以分为两次查询, 更具第一次查询返回的主键应用第二次查询中)、分布式事务等。
            3、常见解决方案
                1、客户端代理, 分片逻辑在应用端, 封装在jar包中, 通过修改或封装jdbc层来实现。当当网的Sharding-jdbc、阿里的TDDL。
                2、中间件代理, 在应用和数据中间加一个代理层。分片逻辑统一维护在中间件中。Mycat、360的Atlas。
                3、什么是分片?
                4、分布式事务?
        5、提高服务器配置, 增加集群数量。(成本较高)
    6、MySQL中in和exists
    mysql中的in语句是把外表和内表作hash连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。
        1. 如果查询的两个表大小相当，那么用in和exists差别不大。
        2. 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。
        3. not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。
        所以无论那个表大，用not exists都比not in要快。
    7、hash链接(hash join) 关系型数据的表连接算法。只能用于有等值连接条件的连接中(例如hash索引)。通常比嵌套连接算法(nest loop)更高效, 尤其是在没有命中索引的情况。
    简单的说就是, 将较小的表加载到内存哈希表中(key是等值连接列的值, value是数据行链表), 然后遍历大表, 将等值列进行hash, 根据hash值在hash表中匹配数据。
    hash连接分为两个阶段: 构建阶段和探测阶段。
        1、构建阶段, 将表加载到内存hash表中。
        2、探测阶段, 根据等值列的hash值, 在hash表中探测数据。
        (一般构建的hash表都是直接全部加载到内存中, 对于无法全部加载到内存中, 可以在构建阶段, 将hash分段存储在磁盘中。在探测阶段, 根据hash进入不同的段中查询数据)
11、MySQL主从复制
    将主数据库的DDL、DML操作通过binlog日志传输到从数据库上, 然后将这些日志在从数据库上重新执行(重做), 达到同步的效果, 从而使主从数据库同步。
    1、作用
        1、主数据库出现问题, 可以切换到从数据库。保证数据库服务的稳定。
        2、可以进行数据库层面的读写分离, 提供数据库并发性能。
        3、可以在从数据上做备份, 减少主库压力, 具有灾备能力。
    2、解决的问题
        1、数据分布: 随意开始或停止复制, 可以在不同地理位置实现分布式负载均衡服务。降低单个数据库压力, 并且在数据库出故障时可以随时切换数据源。
    3、主从复制原理
        1、在主库上把数据操作记录到二进制日志日志文件(binlog)中, 通过同步这些日志文件到从库的中继日志(relay log)中, 在从库重新执行这些日志文件(重做), 恢复主库的操作, 实现主从库同步。
        2、主从复制过程分为三个线程
            1、主库写入日志线程: 主库将数据操作记录到master上binlog中。
            2、从库读取master上binlog日志线程: 从库IO线程从master上拉去binlog日志, 写入到中继日志中。如果有未同步的就读取, 没有就等待。
            3、从库重做线程: 从库从执行中继日志中的SQL, 恢复主库操作。
12、事务的特性及实现原理
13、间隙锁
14、索引下推
15、MVCC
16、乐观锁和悲观锁的实现方式
17、in和exists区别，使用场景，实现
18、分库分表解决方案 及可能遇到的问题
19、MySQL分布式id解决方案
20、查看各阶段执行时间命令
21、优化器都做了那些优化
22、主从复制延时问题
23、常用线程池及区别和使用场景
24、哈希索引、与常规索引
25、MyCat  sharding-jdbc
26、Mysql的binlog有几种录入格式？分别有什么区别？
27、InnoDB引擎的4大特性
